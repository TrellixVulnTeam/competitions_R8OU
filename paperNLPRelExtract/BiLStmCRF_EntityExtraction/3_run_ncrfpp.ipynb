{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run NCRFpp\n",
    "\n",
    "## 1. Training \n",
    "## 2. Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Training\n",
    "#### 使用不同的config文件训练不同参数的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### use # to comment out the configure item\r\n",
      "\r\n",
      "### I/O ###\r\n",
      "train_dir=./NCRFpp/data/conll_2003_simple/train.bmes\r\n",
      "dev_dir=./NCRFpp/data/conll_2003_simple/dev.bmes\r\n",
      "test_dir=./NCRFpp/data/conll_2003_simple/test.bmes\r\n",
      "model_dir=./NCRFpp/saved_models/bilstm-crf\r\n",
      "word_emb_dir=./NCRFpp/data/glove.6B.100d.txt\r\n",
      "\r\n",
      "#raw_dir=\r\n",
      "#decode_dir=\r\n",
      "#dset_dir=\r\n",
      "#load_model_dir=\r\n",
      "#char_emb_dir=\r\n",
      "\r\n",
      "norm_word_emb=False\r\n",
      "norm_char_emb=False\r\n",
      "number_normalized=True\r\n",
      "seg=True\r\n",
      "word_emb_dim=100\r\n",
      "char_emb_dim=30\r\n",
      "\r\n",
      "###NetworkConfiguration###\r\n",
      "use_crf=True\r\n",
      "use_char=False\r\n",
      "word_seq_feature=LSTM\r\n",
      "char_seq_feature=CNN\r\n",
      "#feature=[POS] emb_size=20\r\n",
      "#feature=[Cap] emb_size=20\r\n",
      "#nbest=1\r\n",
      "\r\n",
      "###TrainingSetting###\r\n",
      "status=train\r\n",
      "optimizer=ADAM\r\n",
      "iteration=10\r\n",
      "batch_size=32\r\n",
      "ave_batch_loss=True\r\n",
      "\r\n",
      "###Hyperparameters###\r\n",
      "cnn_layer=4\r\n",
      "char_hidden_dim=50\r\n",
      "hidden_dim=200\r\n",
      "dropout=0.5\r\n",
      "lstm_layer=1\r\n",
      "bilstm=True\r\n",
      "learning_rate=0.0003\r\n",
      "lr_decay=0.05\r\n",
      "momentum=0\r\n",
      "l2=1e-8\r\n",
      "gpu=True\r\n",
      "#clip=\r\n"
     ]
    }
   ],
   "source": [
    "!cat NCRFpp/train.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed num: 42\n",
      "MODEL: train\n",
      "Load pretrained word embedding, norm: False, dir: ./NCRFpp/data/glove.6B.100d.txt\n",
      "Embedding:\n",
      "     pretrain word:400000, prefect match:11415, case_match:11656, oov:2234, oov%:0.08827945941673912\n",
      "Training model...\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "DATA SUMMARY START:\n",
      " I/O:\n",
      "     Start   Sequence   Laebling   task...\n",
      "     Tag          scheme: BIO\n",
      "     Split         token:  ||| \n",
      "     MAX SENTENCE LENGTH: 250\n",
      "     MAX   WORD   LENGTH: -1\n",
      "     Number   normalized: True\n",
      "     Word  alphabet size: 25306\n",
      "     Char  alphabet size: 78\n",
      "     Label alphabet size: 10\n",
      "     Word embedding  dir: ./NCRFpp/data/glove.6B.100d.txt\n",
      "     Char embedding  dir: None\n",
      "     Word embedding size: 100\n",
      "     Char embedding size: 30\n",
      "     Norm   word     emb: False\n",
      "     Norm   char     emb: False\n",
      "     Train  file directory: ./NCRFpp/data/conll_2003_simple/train.bmes\n",
      "     Dev    file directory: ./NCRFpp/data/conll_2003_simple/dev.bmes\n",
      "     Test   file directory: ./NCRFpp/data/conll_2003_simple/test.bmes\n",
      "     Raw    file directory: None\n",
      "     Dset   file directory: None\n",
      "     Model  file directory: ./NCRFpp/saved_models/bilstm-crf\n",
      "     Loadmodel   directory: None\n",
      "     Decode file directory: None\n",
      "     Train instance number: 14986\n",
      "     Dev   instance number: 3465\n",
      "     Test  instance number: 3683\n",
      "     Raw   instance number: 0\n",
      "     FEATURE num: 0\n",
      " ++++++++++++++++++++++++++++++++++++++++\n",
      " Model Network:\n",
      "     Model        use_crf: True\n",
      "     Model word extractor: LSTM\n",
      "     Model       use_char: False\n",
      " ++++++++++++++++++++++++++++++++++++++++\n",
      " Training:\n",
      "     Optimizer: ADAM\n",
      "     Iteration: 10\n",
      "     BatchSize: 32\n",
      "     Average  batch   loss: True\n",
      " ++++++++++++++++++++++++++++++++++++++++\n",
      " Hyperparameters:\n",
      "     Hyper              lr: 0.0003\n",
      "     Hyper        lr_decay: 0.05\n",
      "     Hyper         HP_clip: None\n",
      "     Hyper        momentum: 0.0\n",
      "     Hyper              l2: 1e-08\n",
      "     Hyper      hidden_dim: 200\n",
      "     Hyper         dropout: 0.5\n",
      "     Hyper      lstm_layer: 1\n",
      "     Hyper          bilstm: True\n",
      "     Hyper             GPU: True\n",
      "DATA SUMMARY END.\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "build sequence labeling network...\n",
      "use_char:  False\n",
      "word feature extractor:  LSTM\n",
      "use crf:  True\n",
      "build word sequence feature extractor: LSTM...\n",
      "build word representation...\n",
      "build CRF...\n",
      "Epoch: 0/10\n",
      "Shuffle: first input word list: [1567, 4044, 10146, 237, 2656, 12133, 10]\n",
      "     Instance: 4000; Time: 16.49s; loss: 1802.7417; acc: 44178/55640=0.7940\n",
      "     Instance: 8000; Time: 15.97s; loss: 1119.0157; acc: 89957/110597=0.8134\n",
      "     Instance: 12000; Time: 15.94s; loss: 865.6561; acc: 136162/164439=0.8280\n",
      "     Instance: 14986; Time: 11.85s; loss: 562.3373; acc: 171356/204566=0.8377\n",
      "Epoch: 0 training finished. Time: 60.25s, speed: 248.71st/s,  total loss: 4349.750764846802\n",
      "totalloss: 4349.750764846802\n",
      "Right token =  46138  All token =  51577  acc =  0.8945460185741707\n",
      "Dev: time: 4.31s, speed: 813.14st/s; acc: 0.8945, p: 0.6902, r: 0.3475, f: 0.4623\n",
      "Exceed previous best f score: -10\n",
      "Save current best model in file: ./NCRFpp/saved_models/bilstm-crf.0.model\n",
      "Right token =  41613  All token =  46665  acc =  0.8917389906782385\n",
      "Test: time: 4.62s, speed: 806.11st/s; acc: 0.8917, p: 0.6148, r: 0.3660, f: 0.4588\n",
      "Epoch: 1/10\n",
      "Shuffle: first input word list: [2193, 14]\n",
      "     Instance: 4000; Time: 15.98s; loss: 665.7253; acc: 48392/54376=0.8900\n",
      "     Instance: 8000; Time: 16.20s; loss: 601.1241; acc: 98974/110434=0.8962\n",
      "     Instance: 12000; Time: 15.74s; loss: 527.1035; acc: 148182/164574=0.9004\n",
      "     Instance: 14986; Time: 12.07s; loss: 375.3708; acc: 184611/204566=0.9025\n",
      "Epoch: 1 training finished. Time: 60.00s, speed: 249.76st/s,  total loss: 2169.323664665222\n",
      "totalloss: 2169.323664665222\n",
      "Right token =  48125  All token =  51577  acc =  0.9330709424743587\n",
      "Dev: time: 4.05s, speed: 864.13st/s; acc: 0.9331, p: 0.7608, r: 0.5985, f: 0.6699\n",
      "Exceed previous best f score: 0.4622789344078801\n",
      "Save current best model in file: ./NCRFpp/saved_models/bilstm-crf.1.model\n",
      "Right token =  43354  All token =  46665  acc =  0.9290474659809279\n",
      "Test: time: 3.87s, speed: 964.73st/s; acc: 0.9290, p: 0.6963, r: 0.5845, f: 0.6355\n",
      "Epoch: 2/10\n",
      "Shuffle: first input word list: [271, 8101, 231, 94, 5649, 39, 19851, 15715, 1017, 11922, 230, 12021, 157, 279, 41, 374, 6, 4510, 398, 371, 438, 555, 4512, 5805, 80, 11973, 618, 1536, 4492, 72, 158, 436, 157, 41, 5340, 18, 19, 20, 10]\n",
      "     Instance: 4000; Time: 15.93s; loss: 456.3907; acc: 49938/54329=0.9192\n",
      "     Instance: 8000; Time: 16.16s; loss: 431.2756; acc: 100097/108671=0.9211\n",
      "     Instance: 12000; Time: 17.52s; loss: 400.1092; acc: 151085/163498=0.9241\n",
      "     Instance: 14986; Time: 13.14s; loss: 294.4933; acc: 189299/204566=0.9254\n",
      "Epoch: 2 training finished. Time: 62.74s, speed: 238.85st/s,  total loss: 1582.2687728404999\n",
      "totalloss: 1582.2687728404999\n",
      "Right token =  48944  All token =  51577  acc =  0.9489501134226497\n",
      "Dev: time: 4.57s, speed: 766.76st/s; acc: 0.9490, p: 0.8247, r: 0.7045, f: 0.7598\n",
      "Exceed previous best f score: 0.6699321778447624\n",
      "Save current best model in file: ./NCRFpp/saved_models/bilstm-crf.2.model\n",
      "Right token =  44098  All token =  46665  acc =  0.9449908925318762\n",
      "Test: time: 4.25s, speed: 878.08st/s; acc: 0.9450, p: 0.7636, r: 0.6829, f: 0.7210\n",
      "Epoch: 3/10\n",
      "Shuffle: first input word list: [296, 296, 296, 296]\n",
      "     Instance: 4000; Time: 16.33s; loss: 358.9905; acc: 50920/54430=0.9355\n",
      "     Instance: 8000; Time: 16.10s; loss: 350.6109; acc: 101984/108985=0.9358\n",
      "     Instance: 12000; Time: 16.30s; loss: 334.5279; acc: 153392/163692=0.9371\n",
      "     Instance: 14986; Time: 12.37s; loss: 245.9154; acc: 191890/204566=0.9380\n",
      "Epoch: 3 training finished. Time: 61.10s, speed: 245.25st/s,  total loss: 1290.0446891784668\n",
      "totalloss: 1290.0446891784668\n",
      "Right token =  49660  All token =  51577  acc =  0.9628322701979565\n",
      "Dev: time: 4.44s, speed: 790.93st/s; acc: 0.9628, p: 0.8662, r: 0.7943, f: 0.8287\n",
      "Exceed previous best f score: 0.7598475222363406\n",
      "Save current best model in file: ./NCRFpp/saved_models/bilstm-crf.3.model\n",
      "Right token =  44579  All token =  46665  acc =  0.9552984035144112\n",
      "Test: time: 4.29s, speed: 870.50st/s; acc: 0.9553, p: 0.8162, r: 0.7555, f: 0.7847\n",
      "Epoch: 4/10\n",
      "Shuffle: first input word list: [135, 304, 8435, 710, 237, 5479, 783, 41, 96, 398, 966, 67, 163, 138, 7699, 10]\n",
      "     Instance: 4000; Time: 15.88s; loss: 302.3325; acc: 51289/54354=0.9436\n",
      "     Instance: 8000; Time: 16.14s; loss: 281.6077; acc: 102176/108049=0.9456\n",
      "     Instance: 12000; Time: 16.07s; loss: 295.0578; acc: 153851/162592=0.9462\n",
      "     Instance: 14986; Time: 12.13s; loss: 210.4492; acc: 193710/204566=0.9469\n",
      "Epoch: 4 training finished. Time: 60.22s, speed: 248.84st/s,  total loss: 1089.4470878839493\n",
      "totalloss: 1089.4470878839493\n",
      "Right token =  49893  All token =  51577  acc =  0.967349787696066\n",
      "Dev: time: 4.11s, speed: 852.61st/s; acc: 0.9673, p: 0.8796, r: 0.8154, f: 0.8463\n",
      "Exceed previous best f score: 0.8287244315687823\n",
      "Save current best model in file: ./NCRFpp/saved_models/bilstm-crf.4.model\n",
      "Right token =  44725  All token =  46665  acc =  0.9584270866816672\n",
      "Test: time: 3.88s, speed: 963.50st/s; acc: 0.9584, p: 0.8345, r: 0.7741, f: 0.8032\n",
      "Epoch: 5/10\n",
      "Shuffle: first input word list: [2568, 39, 6376, 10500, 382]\n",
      "     Instance: 4000; Time: 16.03s; loss: 259.1074; acc: 52672/55262=0.9531\n",
      "     Instance: 8000; Time: 15.83s; loss: 250.5569; acc: 103848/108940=0.9533\n",
      "     Instance: 12000; Time: 16.08s; loss: 242.7600; acc: 156113/163544=0.9546\n",
      "     Instance: 14986; Time: 12.02s; loss: 196.5316; acc: 195123/204566=0.9538\n",
      "Epoch: 5 training finished. Time: 59.96s, speed: 249.93st/s,  total loss: 948.9558174610138\n",
      "totalloss: 948.9558174610138\n",
      "Right token =  49918  All token =  51577  acc =  0.9678344998739749\n",
      "Dev: time: 4.07s, speed: 860.25st/s; acc: 0.9678, p: 0.8946, r: 0.8142, f: 0.8525\n",
      "Exceed previous best f score: 0.8462882096069869\n",
      "Save current best model in file: ./NCRFpp/saved_models/bilstm-crf.5.model\n",
      "Right token =  44754  All token =  46665  acc =  0.959048537447766\n",
      "Test: time: 3.87s, speed: 967.32st/s; acc: 0.9590, p: 0.8482, r: 0.7714, f: 0.8080\n",
      "Epoch: 6/10\n",
      "Shuffle: first input word list: [8771, 317, 8695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Instance: 4000; Time: 15.95s; loss: 229.7742; acc: 52125/54460=0.9571\n",
      "     Instance: 8000; Time: 16.04s; loss: 227.2406; acc: 104554/109161=0.9578\n",
      "     Instance: 12000; Time: 16.94s; loss: 221.7079; acc: 156219/163079=0.9579\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"./NCRFpp/main.py\", line 559, in <module>\n",
      "[E thread_pool.cpp:112] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:112] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:112] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:112] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "    train(data)\n",
      "  File \"./NCRFpp/main.py\", line 435, in train\n",
      "    optimizer.step()\n",
      "  File \"/Applications/anaconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 26, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Applications/anaconda3/lib/python3.8/site-packages/torch/optim/adam.py\", line 108, in step\n",
      "    F.adam(params_with_grad,\n",
      "  File \"/Applications/anaconda3/lib/python3.8/site-packages/torch/optim/functional.py\", line 86, in adam\n",
      "    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# 更改模型训练参数，训练模型\n",
    "!python ./NCRFpp/main.py --config NCRFpp/train.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Decode ###\r\n",
      "status=decode\r\n",
      "raw_dir=./NCRFpp/data/conll_2003_simple/test.bmes\r\n",
      "nbest=1\r\n",
      "decode_dir=./NCRFpp/data/conll_2003_simple/test.out\r\n",
      "dset_dir=./NCRFpp/saved_models/bilstm-crf.dset\r\n",
      "load_model_dir=./NCRFpp/saved_models/bilstm-crf.9.model\r\n"
     ]
    }
   ],
   "source": [
    "!cat NCRFpp/decode.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed num: 42\n",
      "MODEL: decode\n",
      "./NCRFpp/data/conll_2003_simple/test.bmes\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "DATA SUMMARY START:\n",
      " I/O:\n",
      "     Start   Sequence   Laebling   task...\n",
      "     Tag          scheme: BIO\n",
      "     Split         token:  ||| \n",
      "     MAX SENTENCE LENGTH: 250\n",
      "     MAX   WORD   LENGTH: -1\n",
      "     Number   normalized: True\n",
      "     Word  alphabet size: 25306\n",
      "     Char  alphabet size: 78\n",
      "     Label alphabet size: 10\n",
      "     Word embedding  dir: ./NCRFpp/data/glove.6B.100d.txt\n",
      "     Char embedding  dir: None\n",
      "     Word embedding size: 100\n",
      "     Char embedding size: 30\n",
      "     Norm   word     emb: False\n",
      "     Norm   char     emb: False\n",
      "     Train  file directory: ./NCRFpp/data/conll_2003_simple/train.bmes\n",
      "     Dev    file directory: ./NCRFpp/data/conll_2003_simple/dev.bmes\n",
      "     Test   file directory: ./NCRFpp/data/conll_2003_simple/test.bmes\n",
      "     Raw    file directory: ./NCRFpp/data/conll_2003_simple/test.bmes\n",
      "     Dset   file directory: ./NCRFpp/saved_models/bilstm-crf.dset\n",
      "     Model  file directory: ./NCRFpp/saved_models/bilstm-crf\n",
      "     Loadmodel   directory: ./NCRFpp/saved_models/bilstm-crf.9.model\n",
      "     Decode file directory: ./NCRFpp/data/conll_2003_simple/test.out\n",
      "     Train instance number: 14986\n",
      "     Dev   instance number: 3465\n",
      "     Test  instance number: 3683\n",
      "     Raw   instance number: 0\n",
      "     FEATURE num: 0\n",
      " ++++++++++++++++++++++++++++++++++++++++\n",
      " Model Network:\n",
      "     Model        use_crf: True\n",
      "     Model word extractor: LSTM\n",
      "     Model       use_char: False\n",
      " ++++++++++++++++++++++++++++++++++++++++\n",
      " Training:\n",
      "     Optimizer: ADAM\n",
      "     Iteration: 10\n",
      "     BatchSize: 32\n",
      "     Average  batch   loss: True\n",
      " ++++++++++++++++++++++++++++++++++++++++\n",
      " Hyperparameters:\n",
      "     Hyper              lr: 0.0003\n",
      "     Hyper        lr_decay: 0.05\n",
      "     Hyper         HP_clip: None\n",
      "     Hyper        momentum: 0.0\n",
      "     Hyper              l2: 1e-08\n",
      "     Hyper      hidden_dim: 200\n",
      "     Hyper         dropout: 0.5\n",
      "     Hyper      lstm_layer: 1\n",
      "     Hyper          bilstm: True\n",
      "     Hyper             GPU: True\n",
      "DATA SUMMARY END.\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "nbest: 1\n",
      "Load Model from file:  ./NCRFpp/saved_models/bilstm-crf\n",
      "build sequence labeling network...\n",
      "use_char:  False\n",
      "word feature extractor:  LSTM\n",
      "use crf:  True\n",
      "build word sequence feature extractor: LSTM...\n",
      "build word representation...\n",
      "build CRF...\n",
      "Traceback (most recent call last):\n",
      "  File \"./NCRFpp/main.py\", line 569, in <module>\n",
      "    decode_results, pred_scores = load_model_decode(data, 'raw')\n",
      "  File \"./NCRFpp/main.py\", line 495, in load_model_decode\n",
      "    model.load_state_dict(torch.load(data.load_model_dir))\n",
      "  File \"/Applications/anaconda3/lib/python3.8/site-packages/torch/serialization.py\", line 595, in load\n",
      "    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n",
      "  File \"/Applications/anaconda3/lib/python3.8/site-packages/torch/serialization.py\", line 774, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"/Applications/anaconda3/lib/python3.8/site-packages/torch/serialization.py\", line 730, in persistent_load\n",
      "    deserialized_objects[root_key] = restore_location(obj, location)\n",
      "  File \"/Applications/anaconda3/lib/python3.8/site-packages/torch/serialization.py\", line 175, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"/Applications/anaconda3/lib/python3.8/site-packages/torch/serialization.py\", line 151, in _cuda_deserialize\n",
      "    device = validate_cuda_device(location)\n",
      "  File \"/Applications/anaconda3/lib/python3.8/site-packages/torch/serialization.py\", line 135, in validate_cuda_device\n",
      "    raise RuntimeError('Attempting to deserialize object on a CUDA '\n",
      "RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n"
     ]
    }
   ],
   "source": [
    "# 更改模型预测参数\n",
    "!python ./NCRFpp/main.py --config NCRFpp/decode.config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
